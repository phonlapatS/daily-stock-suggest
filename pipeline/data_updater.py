#!/usr/bin/env python
"""
data_updater.py - Scalable Stock Data Pipeline
===============================================

Purpose: ‡∏î‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏ö‡∏ö Incremental (‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà)
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 100+ ‡∏´‡∏∏‡πâ‡∏ô
- ‡πÉ‡∏ä‡πâ Parquet format (‡πÄ‡∏£‡πá‡∏ß, ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î)
- Smart Update (‡∏î‡∏∂‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡πÄ‡∏ï‡πá‡∏°, ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏´‡∏°‡πà)
- Error Handling (1 ‡∏´‡∏∏‡πâ‡∏ô‡∏û‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏≠‡∏∑‡πà‡∏ô)
- Rate Limiting (‡πÑ‡∏°‡πà‡πÇ‡∏î‡∏ô ban)

Author: Stock Prediction System
Date: 2026-01-14
"""

import os
import sys
import time
import pandas as pd
from pathlib import Path
from datetime import datetime
from tvDatafeed import TvDatafeed, Interval

# ================================
# Configuration
# ================================

DATA_DIR = "data/stocks"  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
INITIAL_BARS = 3000  # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 12 ‡∏õ‡∏µ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö daily)
UPDATE_BARS = 100  # ‡∏î‡∏∂‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 100 ‡∏ß‡∏±‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£)
RATE_LIMIT_SECONDS = 1.0  # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏î‡∏∂‡∏á (‡πÑ‡∏°‡πà‡πÇ‡∏î‡∏ô ban)

# ================================
# Dynamic Stock List Generation
# ================================

def get_all_thai_stocks():
    """
    ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å starfishX
    
    Returns:
        list: List of {'symbol': 'PTT', 'exchange': 'SET'}
    """
    try:
        import starfishX as sx
        
        print("üì° Fetching all Thai stocks from starfishX...")
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        stocks_df = sx.getStockName()
        
        if stocks_df is None or stocks_df.empty:
            raise ValueError("No stocks returned from starfishX")
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô format ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        stock_list = []
        
        for symbol in stocks_df['symbol'].tolist():
            # TradingView ‡πÉ‡∏ä‡πâ 'SET' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (SET + mai)
            stock_list.append({
                'symbol': symbol,
                'exchange': 'SET'
            })
        
        print(f"‚úÖ Found {len(stock_list)} Thai stocks")
        return stock_list
        
    except Exception as e:
        print(f"‚ö†Ô∏è Warning: Failed to fetch from starfishX: {e}")
        print("üìã Using fallback stock list...")
        
        # Fallback: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏∏‡πâ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        return [
            {'symbol': 'PTT', 'exchange': 'SET'},
            {'symbol': 'DELTA', 'exchange': 'SET'},
            {'symbol': 'AOT', 'exchange': 'SET'},
            {'symbol': 'KBANK', 'exchange': 'SET'},
            {'symbol': 'CPALL', 'exchange': 'SET'},
            {'symbol': 'ADVANC', 'exchange': 'SET'},
            {'symbol': 'BDMS', 'exchange': 'SET'},
            {'symbol': 'BBL', 'exchange': 'SET'},
            {'symbol': 'SCB', 'exchange': 'SET'},
            {'symbol': 'TOP', 'exchange': 'SET'},
        ]


# ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏ö‡∏ö Dynamic
STOCK_LIST = get_all_thai_stocks()


class StockDataUpdater:
    """
    Data Pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô
    
    Features:
    - Incremental Update (‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏´‡∏°‡πà)
    - Parquet Storage (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà 10x ‡∏Å‡∏ß‡πà‡∏≤ CSV)
    - Deduplication (‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥)
    - Error Recovery (‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà error)
    """
    
    def __init__(self, data_dir=DATA_DIR):
        """
        Args:
            data_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        """
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ TradingView
        print("üîå Connecting to TradingView...")
        self.tv = TvDatafeed()
        print("‚úÖ Connected!")
        
        self.stats = {
            'total': 0,
            'initial_load': 0,
            'incremental_update': 0,
            'failed': 0,
            'skipped': 0
        }
    
    def get_file_path(self, symbol, exchange):
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö parquet file
        
        Returns:
            Path: data/stocks/PTT_SET.parquet
        """
        filename = f"{symbol}_{exchange}.parquet"
        return self.data_dir / filename
    
    def load_existing_data(self, file_path):
        """
        ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏≤‡∏Å parquet
        
        Returns:
            DataFrame or None
        """
        if not file_path.exists():
            return None
        
        try:
            df = pd.read_parquet(file_path)
            df.index = pd.to_datetime(df.index)
            return df
        except Exception as e:
            print(f"      ‚ùå Error loading file: {e}")
            return None
    
    def fetch_data(self, symbol, exchange, n_bars):
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å TradingView
        
        Args:
            symbol: ‡∏£‡∏´‡∏±‡∏™‡∏´‡∏∏‡πâ‡∏ô
            exchange: ‡∏ï‡∏•‡∏≤‡∏î
            n_bars: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô bars
        
        Returns:
            DataFrame or None
        """
        try:
            df = self.tv.get_hist(
                symbol=symbol,
                exchange=exchange,
                interval=Interval.in_daily,
                n_bars=n_bars
            )
            
            if df is not None and not df.empty:
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° % change
                df['pct_change'] = df['close'].pct_change() * 100
                return df
            
            return None
            
        except Exception as e:
            print(f"      ‚ùå Error fetching: {e}")
            return None
    
    def merge_and_deduplicate(self, old_df, new_df):
        """
        ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ + ‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥
        
        Logic:
        1. Concatenate old + new
        2. Remove duplicates (keep last = ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà)
        3. Sort by date
        
        Args:
            old_df: DataFrame ‡πÄ‡∏Å‡πà‡∏≤
            new_df: DataFrame ‡πÉ‡∏´‡∏°‡πà
        
        Returns:
            DataFrame: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß
        """
        # ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô
        combined = pd.concat([old_df, new_df])
        
        # ‡∏•‡∏ö‡∏ã‡πâ‡∏≥ (‡∏ñ‡πâ‡∏≤ date ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà)
        combined = combined[~combined.index.duplicated(keep='last')]
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° date
        combined = combined.sort_index()
        
        return combined
    
    def update_stock(self, symbol, exchange, index, total):
        """
        ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 1 ‡∏´‡∏∏‡πâ‡∏ô
        
        Strategy:
        - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ‚Üí ‡∏î‡∏∂‡∏á‡πÄ‡∏ï‡πá‡∏° (Initial Load)
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ‚Üí ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏´‡∏°‡πà (Incremental Update)
        
        Args:
            symbol: ‡∏£‡∏´‡∏±‡∏™‡∏´‡∏∏‡πâ‡∏ô
            exchange: ‡∏ï‡∏•‡∏≤‡∏î
            index: ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
            total: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        """
        print(f"\n[{index}/{total}] üìä {symbol} ({exchange})")
        
        file_path = self.get_file_path(symbol, exchange)
        old_data = self.load_existing_data(file_path)
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏Å‡∏µ‡πà bars
        if old_data is None:
            # Case A: Initial Load
            print(f"      üÜï Initial Load - Fetching {INITIAL_BARS} bars...")
            n_bars = INITIAL_BARS
            mode = "initial"
        else:
            # Case B: Incremental Update
            old_count = len(old_data)
            latest_date = old_data.index[-1].strftime('%Y-%m-%d')
            print(f"      ‚ôªÔ∏è Update Mode - Last date: {latest_date} ({old_count} existing bars)")
            print(f"      üì• Fetching {UPDATE_BARS} recent bars...")
            n_bars = UPDATE_BARS
            mode = "update"
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        new_data = self.fetch_data(symbol, exchange, n_bars)
        
        if new_data is None:
            print(f"      ‚ùå Failed - Skipping")
            self.stats['failed'] += 1
            return False
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        if mode == "initial":
            final_data = new_data
            self.stats['initial_load'] += 1
            print(f"      ‚úÖ Saved {len(final_data)} bars (Initial)")
        else:
            # Merge + Deduplicate
            final_data = self.merge_and_deduplicate(old_data, new_data)
            new_rows = len(final_data) - len(old_data)
            
            if new_rows > 0:
                print(f"      ‚úÖ Added {new_rows} new bars (Total: {len(final_data)})")
                self.stats['incremental_update'] += 1
            else:
                print(f"      ‚è≠Ô∏è No new data (Already up-to-date)")
                self.stats['skipped'] += 1
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        final_data.to_parquet(file_path)
        
        return True
    
    def run(self, stock_list, skip_existing=False):
        """
        ‡∏£‡∏±‡∏ô Data Pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        
        Args:
            stock_list: List of {'symbol': 'PTT', 'exchange': 'SET'}
            skip_existing: ‡∏ñ‡πâ‡∏≤ True ‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
        """
        print("\n" + "="*70)
        print("üöÄ Stock Data Pipeline - Starting Update")
        print("="*70)
        print(f"üìÅ Data Directory: {self.data_dir}")
        print(f"üìä Target Stocks: {len(stock_list)}")
        
        # ========================================
        # Incremental Download Logic
        # ========================================
        
        if skip_existing:
            print(f"‚öôÔ∏è Mode: Incremental (Skip Existing)")
            
            # 1. Scan existing files
            existing_files = list(self.data_dir.glob("*.parquet"))
            existing_symbols = set()
            
            for file in existing_files:
                # Extract symbol from filename (e.g., PTT_SET.parquet -> PTT)
                symbol = file.stem.split('_')[0]
                existing_symbols.add(symbol)
            
            # 2. Filter missing stocks
            missing_stocks = [
                stock for stock in stock_list 
                if stock['symbol'] not in existing_symbols
            ]
            
            # 3. Summary
            print(f"üì¶ Found {len(existing_files)} existing files")
            print(f"‚¨áÔ∏è Downloading {len(missing_stocks)} missing stocks...")
            
            # Update stock list to only missing ones
            stock_list = missing_stocks
            
            if not stock_list:
                print("‚úÖ All stocks already downloaded!")
                return
        else:
            print(f"‚öôÔ∏è Mode: Full Update (All Stocks)")
        
        print(f"‚è±Ô∏è Rate Limit: {RATE_LIMIT_SECONDS} sec/stock")
        print("="*70)
        
        start_time = time.time()
        self.stats['total'] = len(stock_list)
        
        for idx, stock in enumerate(stock_list, 1):
            try:
                self.update_stock(
                    stock['symbol'],
                    stock['exchange'],
                    idx,
                    len(stock_list)
                )
            except Exception as e:
                print(f"      ‚ùå Unexpected error: {e}")
                self.stats['failed'] += 1
            
            # Rate Limiting (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏ï‡∏±‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢)
            if idx < len(stock_list):
                time.sleep(RATE_LIMIT_SECONDS)
        
        elapsed = time.time() - start_time
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        self.print_summary(elapsed)
    
    def print_summary(self, elapsed):
        """
        ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        """
        print("\n" + "="*70)
        print("üìä Update Summary")
        print("="*70)
        print(f"‚úÖ Completed: {self.stats['total']} stocks")
        print(f"   üÜï Initial Load: {self.stats['initial_load']} stocks")
        print(f"   ‚ôªÔ∏è Incremental Update: {self.stats['incremental_update']} stocks")
        print(f"   ‚è≠Ô∏è Already Up-to-date: {self.stats['skipped']} stocks")
        print(f"   ‚ùå Failed: {self.stats['failed']} stocks")
        print(f"\n‚è±Ô∏è Time Elapsed: {elapsed:.1f} seconds")
        print(f"   Average: {elapsed/self.stats['total']:.1f} sec/stock")
        print("="*70)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á
        parquet_files = list(self.data_dir.glob("*.parquet"))
        total_size = sum(f.stat().st_size for f in parquet_files)
        
        print(f"\nüíæ Storage:")
        print(f"   Files: {len(parquet_files)} parquet files")
        print(f"   Total Size: {total_size / 1024 / 1024:.2f} MB")
        print(f"   Location: {self.data_dir}")
        print("="*70)


def main(skip_existing=True):
    """
    Main execution
    
    Args:
        skip_existing: ‡∏ñ‡πâ‡∏≤ True ‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡πâ‡∏ß (Default: True)
    """
    print("\nüéØ Stock Data Updater")
    print(f"üìÖ Run Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á updater
    updater = StockDataUpdater(data_dir=DATA_DIR)
    
    # ‡∏£‡∏±‡∏ô pipeline
    updater.run(STOCK_LIST, skip_existing=skip_existing)
    
    print("\n‚úÖ Data Pipeline Complete!")
    print("üí° Tip: ‡∏£‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà\n")


if __name__ == "__main__":
    import sys
    
    # Check command line args
    skip_existing = True  # Default
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--full":
            skip_existing = False
            print("üîÑ Running in FULL mode (update all stocks)")
        elif sys.argv[1] == "--skip":
            skip_existing = True
            print("‚ö° Running in INCREMENTAL mode (skip existing)")
    
    main(skip_existing=skip_existing)
