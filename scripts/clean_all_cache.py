#!/usr/bin/env python
"""
Clean All Cache - ‡∏•‡∏ö cache ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô backtest ‡πÉ‡∏´‡∏°‡πà

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç logic ‡πÉ‡∏ô backtest.py ‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏ß‡∏£‡∏•‡∏ö cache ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ:
1. Backtest ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
2. ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß (threshold, RM, gatekeeper)
3. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
"""

import sys
import os
import glob
import pandas as pd
import io

# Fix encoding for Windows console
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def clean_all_cache():
    """‡∏•‡∏ö cache ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    
    print("="*100)
    print("Clean All Cache - ‡∏•‡∏ö cache ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
    print("="*100)
    print()
    
    deleted_count = 0
    errors = []
    
    # 1. ‡∏•‡∏ö cache files ‡πÉ‡∏ô data/cache/
    cache_dir = 'data/cache'
    if os.path.exists(cache_dir):
        cache_files = glob.glob(os.path.join(cache_dir, '*.csv')) + glob.glob(os.path.join(cache_dir, '*.pkl'))
        for file_path in cache_files:
            try:
                os.remove(file_path)
                deleted_count += 1
                print(f"‚úÖ ‡∏•‡∏ö: {file_path}")
            except Exception as e:
                errors.append(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö {file_path}: {e}")
    
    # 2. ‡∏•‡∏ö trade_history files (‡πÅ‡∏ï‡πà‡πÄ‡∏Å‡πá‡∏ö trade_history.csv ‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô backup)
    logs_dir = 'logs'
    if os.path.exists(logs_dir):
        trade_history_files = glob.glob(os.path.join(logs_dir, 'trade_history_*.csv'))
        for file_path in trade_history_files:
            try:
                os.remove(file_path)
                deleted_count += 1
                print(f"‚úÖ ‡∏•‡∏ö: {file_path}")
            except Exception as e:
                errors.append(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö {file_path}: {e}")
    
    # 3. ‡∏•‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î symbol_performance.csv (‡∏•‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ entries ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á)
    perf_file = 'data/symbol_performance.csv'
    if os.path.exists(perf_file):
        try:
            # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
            df = pd.read_csv(perf_file, on_bad_lines='skip', engine='python')
            original_count = len(df)
            
            # ‡∏•‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô backtest)
            os.remove(perf_file)
            deleted_count += 1
            print(f"‚úÖ ‡∏•‡∏ö: {perf_file} ({original_count} entries)")
        except Exception as e:
            errors.append(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö {perf_file}: {e}")
    
    # 4. ‡∏•‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î full_backtest_results.csv (‡∏•‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ entries ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á)
    full_results_file = 'data/full_backtest_results.csv'
    if os.path.exists(full_results_file):
        try:
            # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
            df = pd.read_csv(full_results_file, on_bad_lines='skip', engine='python')
            original_count = len(df)
            
            # ‡∏•‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô backtest)
            os.remove(full_results_file)
            deleted_count += 1
            print(f"‚úÖ ‡∏•‡∏ö: {full_results_file} ({original_count} entries)")
        except Exception as e:
            errors.append(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö {full_results_file}: {e}")
    
    # 5. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ
    print()
    print("="*100)
    print("‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏•‡∏ö Cache")
    print("="*100)
    print()
    
    if deleted_count > 0:
        print(f"‚úÖ ‡∏•‡∏ö cache ‡πÅ‡∏•‡πâ‡∏ß: {deleted_count} ‡πÑ‡∏ü‡∏•‡πå")
        print()
        print("üìã ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏•‡∏ö:")
        print("   - data/cache/*.csv, *.pkl (cache files)")
        print("   - logs/trade_history_*.csv (trade history)")
        print("   - data/symbol_performance.csv (performance summary)")
        print("   - data/full_backtest_results.csv (full results)")
        print()
        print("üí° ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:")
        print("   1. ‡∏£‡∏±‡∏ô backtest ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®:")
        print("      python scripts/backtest.py --full --bars 2000 --group THAI")
        print("      python scripts/backtest.py --full --bars 2000 --group US")
        print("      python scripts/backtest.py --full --bars 2000 --group CHINA")
        print("      python scripts/backtest.py --full --bars 2000 --group TAIWAN")
        print()
        print("   2. ‡∏£‡∏±‡∏ô calculate_metrics ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á performance summary:")
        print("      python scripts/calculate_metrics.py")
        print()
    else:
        print("‚ÑπÔ∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå cache ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö")
        print()
    
    if errors:
        print("‚ö†Ô∏è  ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î:")
        for error in errors:
            print(f"   {error}")
        print()
    
    return deleted_count

def clean_market_cache(market_group):
    """‡∏•‡∏ö cache ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®"""
    
    print("="*100)
    print(f"Clean Cache for {market_group} - ‡∏•‡∏ö cache ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ {market_group}")
    print("="*100)
    print()
    
    deleted_count = 0
    errors = []
    
    # 1. ‡∏•‡∏ö trade_history ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ô‡∏±‡πâ‡∏ô
    trade_history_file = f'logs/trade_history_{market_group}.csv'
    if os.path.exists(trade_history_file):
        try:
            os.remove(trade_history_file)
            deleted_count += 1
            print(f"‚úÖ ‡∏•‡∏ö: {trade_history_file}")
        except Exception as e:
            errors.append(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö {trade_history_file}: {e}")
    
    # 2. ‡∏•‡∏ö entries ‡∏à‡∏≤‡∏Å symbol_performance.csv
    perf_file = 'data/symbol_performance.csv'
    if os.path.exists(perf_file):
        try:
            df = pd.read_csv(perf_file, on_bad_lines='skip', engine='python')
            original_count = len(df)
            
            # Filter by market group
            if 'Country' in df.columns:
                # Map market_group to country codes
                country_map = {
                    'THAI': ['TH'],
                    'US': ['US'],
                    'CHINA': ['CN', 'HK'],
                    'TAIWAN': ['TW']
                }
                
                countries_to_remove = country_map.get(market_group, [])
                if countries_to_remove:
                    df_cleaned = df[~df['Country'].isin(countries_to_remove)]
                    df_cleaned.to_csv(perf_file, index=False)
                    deleted_count += original_count - len(df_cleaned)
                    print(f"‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î: {perf_file} (‡∏•‡∏ö {original_count - len(df_cleaned)} entries)")
        except Exception as e:
            errors.append(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î {perf_file}: {e}")
    
    # 3. ‡∏•‡∏ö entries ‡∏à‡∏≤‡∏Å full_backtest_results.csv
    full_results_file = 'data/full_backtest_results.csv'
    if os.path.exists(full_results_file):
        try:
            df = pd.read_csv(full_results_file, on_bad_lines='skip', engine='python')
            original_count = len(df)
            
            # Filter by market group (check both 'country' and 'group' columns)
            country_map = {
                'THAI': ['TH', 'GROUP_A_THAI'],
                'US': ['US', 'GROUP_B_US'],
                'CHINA': ['CN', 'HK', 'GROUP_C_CHINA_HK'],
                'TAIWAN': ['TW', 'GROUP_D_TAIWAN']
            }
            
            countries_to_remove = country_map.get(market_group, [])
            if countries_to_remove:
                # Try 'country' column first
                if 'country' in df.columns:
                    df_cleaned = df[~df['country'].isin(countries_to_remove)]
                # Try 'group' column (for full_backtest_results.csv)
                elif 'group' in df.columns:
                    df_cleaned = df[~df['group'].str.contains('|'.join(countries_to_remove), case=False, na=False)]
                else:
                    df_cleaned = df
                
                if len(df_cleaned) < original_count:
                    df_cleaned.to_csv(full_results_file, index=False)
                    deleted_count += original_count - len(df_cleaned)
                    print(f"‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î: {full_results_file} (‡∏•‡∏ö {original_count - len(df_cleaned)} entries)")
        except Exception as e:
            errors.append(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î {full_results_file}: {e}")
    
    # 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ
    print()
    print("="*100)
    print(f"‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏•‡∏ö Cache ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {market_group}")
    print("="*100)
    print()
    
    if deleted_count > 0:
        print(f"‚úÖ ‡∏•‡∏ö cache ‡πÅ‡∏•‡πâ‡∏ß: {deleted_count} ‡πÑ‡∏ü‡∏•‡πå/entries")
        print()
        print(f"üí° ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:")
        print(f"   1. ‡∏£‡∏±‡∏ô backtest ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {market_group}:")
        print(f"      python scripts/backtest.py --full --bars 2000 --group {market_group}")
        print()
        print(f"   2. ‡∏£‡∏±‡∏ô calculate_metrics ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó performance summary:")
        print(f"      python scripts/calculate_metrics.py")
        print()
    else:
        print("‚ÑπÔ∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå cache ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö")
        print()
    
    if errors:
        print("‚ö†Ô∏è  ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î:")
        for error in errors:
            print(f"   {error}")
        print()
    
    return deleted_count

def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Clean cache files for backtest')
    parser.add_argument('--market', type=str, help='Clean cache for specific market (THAI, US, CHINA, TAIWAN)')
    parser.add_argument('--all', action='store_true', help='Clean all cache files')
    
    args = parser.parse_args()
    
    if args.all:
        clean_all_cache()
    elif args.market:
        clean_market_cache(args.market.upper())
    else:
        print("="*100)
        print("Clean Cache - ‡∏•‡∏ö cache files")
        print("="*100)
        print()
        print("Usage:")
        print("  # ‡∏•‡∏ö cache ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
        print("  python scripts/clean_all_cache.py --all")
        print()
        print("  # ‡∏•‡∏ö cache ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®")
        print("  python scripts/clean_all_cache.py --market THAI")
        print("  python scripts/clean_all_cache.py --market US")
        print("  python scripts/clean_all_cache.py --market CHINA")
        print("  python scripts/clean_all_cache.py --market TAIWAN")
        print()
        print("="*100)
        print()
        print("‚ö†Ô∏è  ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:")
        print("   - ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç logic ‡πÉ‡∏ô backtest.py ‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏ß‡∏£‡∏•‡∏ö cache")
        print("   - ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ backtest ‡∏£‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        print("   - ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")
        print()

if __name__ == "__main__":
    main()

