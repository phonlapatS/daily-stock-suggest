#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
generate_summary.py â€” Stock-Level Summary via N+1 Prediction Voting
====================================================================
à¸­à¹ˆà¸²à¸™ Master_Pattern_Stats_NewLogic.csv à¹à¸¥à¹‰à¸§à¸ªà¸£à¹‰à¸²à¸‡ Summary à¸§à¹ˆà¸²à¸«à¸¸à¹‰à¸™à¹à¸•à¹ˆà¸¥à¸°à¸•à¸±à¸§
à¸¡à¸µ "à¸—à¸´à¸¨à¸—à¸²à¸‡à¹€à¸Šà¸´à¸‡à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸¨à¸²à¸ªà¸•à¸£à¹Œ" (Historical Directional Bias) à¹€à¸›à¹‡à¸™ + à¸«à¸£à¸·à¸­ -

à¸«à¸¥à¸±à¸à¸à¸²à¸£ N+1 Voting:
  1. Pattern "+-+" (Length=3) â†’ Base="+-", Outcome="+"
     à¸«à¸¡à¸²à¸¢à¸„à¸§à¸²à¸¡à¸§à¹ˆà¸²: "à¸–à¹‰à¸²à¹€à¸ˆà¸­ +- à¹à¸¥à¹‰à¸§ à¸§à¸±à¸™à¸–à¸±à¸”à¹„à¸›(N+1) à¸‚à¸¶à¹‰à¸™(+)"
  
  2. à¸£à¸§à¸¡ count à¸‚à¸­à¸‡ Outcome + à¸à¸±à¸š - à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸° Base Pattern
     à¸•à¸±à¸§à¹„à¸«à¸™ count à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² = Vote à¸‚à¸­à¸‡ Base à¸™à¸±à¹‰à¸™
  
  3. à¸™à¸±à¸š Vote à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸•à¹ˆà¸­à¸«à¸¸à¹‰à¸™ â†’ à¸ªà¸£à¸¸à¸›à¸§à¹ˆà¸² + à¸«à¸£à¸·à¸­ - à¸Šà¸™à¸°

Usage:
  python scripts/generate_summary.py
"""

import sys
import os
import pandas as pd
import numpy as np

# Fix encoding for Windows
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# Paths
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.dirname(SCRIPT_DIR)
DATA_DIR = os.path.join(PROJECT_DIR, 'data')

MASTER_STATS_FILE = os.path.join(DATA_DIR, 'Master_Pattern_Stats_NewLogic.csv')
OUTPUT_FILE = os.path.join(DATA_DIR, 'Stock_Prediction_History_Summary.csv')

# Threshold: minimum combined count for a Base Pattern to be considered valid
MIN_BASE_COUNT = 30


def main():
    print("=" * 70)
    print("ğŸ“Š N+1 PREDICTION VOTING â€” Stock-Level Summary Generator")
    print("=" * 70)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 1: Load Data
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not os.path.exists(MASTER_STATS_FILE):
        print(f"âŒ Master stats not found: {MASTER_STATS_FILE}")
        sys.exit(1)
    
    df = pd.read_csv(MASTER_STATS_FILE)
    print(f"\nğŸ“‚ Loaded: {MASTER_STATS_FILE}")
    print(f"   Total rows: {len(df):,}")
    print(f"   Unique symbols: {df['Symbol'].nunique()}")
    print(f"   Markets: {', '.join(df['Market'].unique())}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 2: Filter valid lengths (Length >= 2)
    # Pattern must have at least 2 chars to extract Base + Outcome
    # e.g., "++" â†’ Base="+", Outcome="+"
    # Single-char patterns like "+" have no predictive base
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df_valid = df[df['Length'] >= 2].copy()
    print(f"\nğŸ” After filtering Length >= 2: {len(df_valid):,} rows")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 3: Extract Base Pattern & Outcome
    # Pattern "+-+" â†’ Base_Pattern = "+-", Outcome = "+"
    # This represents: "After seeing '+-', the N+1 day was '+'"
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df_valid['Base_Pattern'] = df_valid['Pattern'].str[:-1]   # à¸—à¸¸à¸à¸•à¸±à¸§à¸¢à¸à¹€à¸§à¹‰à¸™à¸•à¸±à¸§à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢
    df_valid['Outcome'] = df_valid['Pattern'].str[-1]          # à¸•à¸±à¸§à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ (+ or -)
    
    print(f"   Extracted Base_Pattern + Outcome")
    print(f"   Sample: Pattern='{df_valid.iloc[0]['Pattern']}' â†’ Base='{df_valid.iloc[0]['Base_Pattern']}', Outcome='{df_valid.iloc[0]['Outcome']}'")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 4: Group and Pivot â€” Count + vs - outcomes per Base
    # For each (Symbol, Base_Pattern):
    #   P_Count = how many times Outcome was "+"
    #   N_Count = how many times Outcome was "-"
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pivot = df_valid.pivot_table(
        index=['Symbol', 'Market', 'Base_Pattern'],
        columns='Outcome',
        values='Count',
        aggfunc='sum',
        fill_value=0
    ).reset_index()
    
    # Ensure both + and - columns exist
    if '+' not in pivot.columns:
        pivot['+'] = 0
    if '-' not in pivot.columns:
        pivot['-'] = 0
    
    pivot = pivot.rename(columns={'+': 'P_Count', '-': 'N_Count'})
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 5: Apply Strict Threshold (Total_Base_Count >= 30)
    # Only keep Base Patterns with enough data to be statistically meaningful
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pivot['Total_Base_Count'] = pivot['P_Count'] + pivot['N_Count']
    
    before_filter = len(pivot)
    pivot_valid = pivot[pivot['Total_Base_Count'] >= MIN_BASE_COUNT].copy()
    after_filter = len(pivot_valid)
    
    print(f"\nğŸ“‹ Base Patterns before threshold: {before_filter:,}")
    print(f"   After Count >= {MIN_BASE_COUNT} filter: {after_filter:,}")
    print(f"   Dropped: {before_filter - after_filter:,} (insufficient data)")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 6: Determine the Base Pattern Winner (Vote)
    # For each Base Pattern:
    #   P_Count > N_Count â†’ vote "+"
    #   N_Count > P_Count â†’ vote "-"
    #   Tied â†’ discard (no clear edge)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def determine_vote(row):
        if row['P_Count'] > row['N_Count']:
            return '+'
        elif row['N_Count'] > row['P_Count']:
            return '-'
        else:
            return None  # Tied â†’ discard
    
    pivot_valid['Vote'] = pivot_valid.apply(determine_vote, axis=1)
    
    # Remove ties
    tied = pivot_valid['Vote'].isna().sum()
    pivot_voted = pivot_valid.dropna(subset=['Vote']).copy()
    
    print(f"\nğŸ—³ï¸  Voting Results:")
    print(f"   Valid votes: {len(pivot_voted):,}")
    print(f"   Tied (discarded): {tied:,}")
    
    # Show some examples
    print(f"\n   --- Sample votes (first 10) ---")
    for _, row in pivot_voted.head(10).iterrows():
        winner = row['Vote']
        p, n = int(row['P_Count']), int(row['N_Count'])
        print(f"   {row['Symbol']:12s} Base='{row['Base_Pattern']:6s}' â†’ +:{p:>4d} vs -:{n:>4d} â†’ Vote: {winner}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 7: Tally Votes per Stock
    # Count how many Base Patterns voted + vs - per Symbol
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    vote_counts = pivot_voted.groupby(['Symbol', 'Market', 'Vote']).size().unstack(fill_value=0).reset_index()
    
    # Ensure both columns exist
    if '+' not in vote_counts.columns:
        vote_counts['+'] = 0
    if '-' not in vote_counts.columns:
        vote_counts['-'] = 0
    
    vote_counts = vote_counts.rename(columns={'+': 'Predict_P', '-': 'Predict_N'})
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 8: Calculate Summary Percentages
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    vote_counts['Total_Valid_Patterns'] = vote_counts['Predict_P'] + vote_counts['Predict_N']
    vote_counts['P_Win_Rate%'] = (vote_counts['Predict_P'] / vote_counts['Total_Valid_Patterns'] * 100).round(1)
    vote_counts['N_Win_Rate%'] = (vote_counts['Predict_N'] / vote_counts['Total_Valid_Patterns'] * 100).round(1)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 9: Determine Final Stock Bias & Win Rate
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 10: Final Data Preparation (Include ALL Stocks)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Get list of all unique symbols/markets from original DF to ensure no one is left behind
    all_stocks = df[['Symbol', 'Market']].drop_duplicates()
    
    # Merge voting results back to all_stocks
    # Symbols with no valid votes (due to low count or tie) will have NaNs
    final_df = pd.merge(all_stocks, vote_counts, on=['Symbol', 'Market'], how='left')
    
    # Fill NaNs
    final_df['Predict_P'] = final_df['Predict_P'].fillna(0).astype(int)
    final_df['Predict_N'] = final_df['Predict_N'].fillna(0).astype(int)
    final_df['Total_Valid_Patterns'] = final_df['Total_Valid_Patterns'].fillna(0).astype(int)
    
    # Recalculate rates (handle divide by zero)
    final_df['P_Win_Rate%'] = (final_df['Predict_P'] / final_df['Total_Valid_Patterns'] * 100).fillna(0).round(1)
    final_df['N_Win_Rate%'] = (final_df['Predict_N'] / final_df['Total_Valid_Patterns'] * 100).fillna(0).round(1)

    # Function to determine Bias with format "ğŸŸ© P (XX%)", "ğŸŸ¥ N (XX%)"
    def determine_bias_final(row):
        total_valid = row['Total_Valid_Patterns']
        if total_valid == 0:
            return "â¬œ ." # Insufficient Data
            
        p_rate = row['P_Win_Rate%']
        n_rate = row['N_Win_Rate%']
        
        if p_rate > n_rate:
            return f"ğŸŸ© P ({int(round(p_rate))}%)"
        elif n_rate > p_rate:
            return f"ğŸŸ¥ N ({int(round(n_rate))}%)"
        else:
            return f"â¬œ = ({int(round(p_rate))}%)"

    final_df['Bias'] = final_df.apply(determine_bias_final, axis=1)

    # Rename for output
    rename_map = {
        'Total_Valid_Patterns': 'Valid Pattern',
        'Predict_P': '+ Pattern',
        'Predict_N': '- Pattern',
    }
    final_df = final_df.rename(columns=rename_map)
    
    # Select Columns
    output_cols = ['Symbol', 'Market', 'Valid Pattern', '+ Pattern', '- Pattern', 'Bias']
    final_df = final_df[output_cols]
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 10.5: Map Symbols to Readable Names
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Load mapping from config
    try:
        sys.path.append(PROJECT_DIR) # Ensure we can import config from root
        import config
        symbol_map = {}
        for group in config.ASSET_GROUPS.values():
            for asset in group['assets']:
                if 'name' in asset:
                    symbol_map[asset['symbol']] = asset['name']
        
        # Force Symbol to string to match config keys (which are strings like '700')
        final_df['Symbol'] = final_df['Symbol'].astype(str)
        
        # Apply mapping (if not found, keep original)
        final_df['Symbol'] = final_df['Symbol'].map(symbol_map).fillna(final_df['Symbol'])
        print(f"âœ… Mapped {len(symbol_map)} symbols to readable names.")
        
    except ImportError:
        print("âš ï¸ Could not import config.py. Skipping symbol mapping.")
    
    # Save to CSV
    final_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ Saved summary to: {OUTPUT_FILE}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 11: Display Tables by Market
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    markets = sorted(final_df['Market'].unique())
    
    for market in markets:
        market_df = final_df[final_df['Market'] == market].sort_values(by='Symbol')
        
        print(f"\n{'=' * 80}")
        print(f"ğŸŒ MARKET: {market} ({len(market_df)} stocks)")
        print(f"{'=' * 80}")
        print(f"{'Symbol':<12} {'Valid Pattern':<15} {'+ Pattern':<12} {'- Pattern':<12} {'Bias':<15}")
        print("-" * 80)
        
        for _, row in market_df.iterrows():
            print(f"{row['Symbol']:<12} {row['Valid Pattern']:<15} {row['+ Pattern']:<12} {row['- Pattern']:<12} {row['Bias']:<15}")
        
        print("-" * 80)

    print(f"\nâœ… Report Generated Successfully.")

if __name__ == '__main__':
    main()
